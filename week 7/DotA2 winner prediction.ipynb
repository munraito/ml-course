{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Предсказание победителя в DotA 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "disable warnings and import all needed libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_score, ShuffleSplit, GridSearchCV\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для начала загрузим признаки:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 20.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "features = pd.read_csv('data/features.csv', index_col='match_id')\n",
    "features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Удалим признаки, которых нет в тестовой выборке <br>\n",
    "Узнаем есть ли в признаках пропуски (пропуски скорее всего означают, что события не произошло за первые 5 минут) <br>\n",
    "Заполним пропуски нулями"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['first_blood_time', 'first_blood_team', 'first_blood_player1', 'first_blood_player2', 'radiant_bottle_time', 'radiant_courier_time', 'radiant_flying_courier_time', 'radiant_first_ward_time', 'dire_bottle_time', 'dire_courier_time', 'dire_flying_courier_time', 'dire_first_ward_time']\n"
     ]
    }
   ],
   "source": [
    "train_df = features.drop(columns=['duration', 'radiant_win', 'tower_status_radiant', 'tower_status_dire',\n",
    "                                  'barracks_status_radiant', 'barracks_status_dire'])\n",
    "print(train_df.columns[train_df.isna().any()].tolist())\n",
    "train_df = train_df.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выделим **X_train** и **y_train**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_df.values\n",
    "y_train = features['radiant_win'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Gradient Boosting 5-Fold cross-validation\n",
    "Обучим модель на разном количестве деревьев "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 47s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "cv = ShuffleSplit(n_splits=5, test_size=0.3, random_state=17)\n",
    "\n",
    "model_gb1 = GradientBoostingClassifier(n_estimators=10)\n",
    "\n",
    "# calcuate ROC-AUC for each split\n",
    "cv_scores_gb1 = cross_val_score(model_gb1, X_train, y_train, cv=cv, scoring='roc_auc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На 10 деревьях 0.6638"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6638212118591542 0.0027055733382682304\n"
     ]
    }
   ],
   "source": [
    "print(cv_scores_gb1.mean(), cv_scores_gb1.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 7min 9s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model_gb2 = GradientBoostingClassifier(n_estimators=20)\n",
    "cv_scores_gb2 = cross_val_score(model_gb2, X_train, y_train, cv=cv, scoring='roc_auc')\n",
    "\n",
    "model_gb3 = GradientBoostingClassifier(n_estimators=30)\n",
    "cv_scores_gb3 = cross_val_score(model_gb3, X_train, y_train, cv=cv, scoring='roc_auc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "model_gb250 = GradientBoostingClassifier(n_estimators=250)\n",
    "cv_scores_gb250 = cross_val_score(model_gb250, X_train, y_train, cv=cv, scoring='roc_auc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6809035362077415 0.002869911864414055\n",
      "0.688028167191805 0.002920434580041873\n"
     ]
    }
   ],
   "source": [
    "print(cv_scores_gb2.mean(), cv_scores_gb2.std())\n",
    "print(cv_scores_gb3.mean(), cv_scores_gb3.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7148684121164571 0.0018273112133065678\n"
     ]
    }
   ],
   "source": [
    "print(cv_scores_gb250.mean(), cv_scores_gb250.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4min 12s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model_gb3 = GradientBoostingClassifier(n_estimators=30)\n",
    "cv_scores_gb3 = cross_val_score(model_gb3, X_train, y_train, cv=cv, scoring='roc_auc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2min 30s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model_gb3_1 = GradientBoostingClassifier(n_estimators=30, max_depth=2)\n",
    "cv_scores_gb3_1 = cross_val_score(model_gb3_1, X_train, y_train, cv=cv, scoring='roc_auc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6812550642543101"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_scores_gb3_1.mean() #max_depth=2, n_estimators=30 => 0.6812550642543101"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "При увеличении количества деревьев растет качество, а так же время обучения модели. Ускорить обучение можно уменьшив другие параметры (например, max_depth), но из-за этого пострадает качество <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try **Logistic Regression** <br>\n",
    "Функция для нормировки признаков и получения cross_val_score по ROC_AUC:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_logreg_score(X):\n",
    "    X_train_scaled = StandardScaler().fit_transform(X)\n",
    "    logit = LogisticRegression(C=1, penalty='l2')\n",
    "    cv_scores_logit = cross_val_score(logit, X_train_scaled, y_train, cv=cv, scoring='roc_auc')\n",
    "    return [cv_scores_logit.mean(), cv_scores_logit.std()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сходу получаем 71%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 43.8 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.7152442684469731, 0.0023618816025120838]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "get_logreg_score(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вспомним тот факт, что в выборке присутвуют категориальные признаки, попробуем удалить их и замерить качество еще раз:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7153294734641201, 0.0022947329444929403]\n",
      "Wall time: 31.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "cat_features = ['lobby_type', 'r1_hero', 'r2_hero', 'r3_hero', 'r4_hero', 'r5_hero', 'd1_hero', 'd2_hero', 'd3_hero', 'd4_hero', 'd5_hero']\n",
    "X_train = train_df.drop(columns=cat_features).values\n",
    "print(get_logreg_score(X_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сколько всего различных героев существует в выборке?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "108"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heroes = ['r1_hero', 'r2_hero', 'r3_hero','r4_hero', 'r5_hero', 'd1_hero', 'd2_hero', 'd3_hero', 'd4_hero', 'd5_hero']\n",
    "len(np.unique(train_df[heroes].values))\n",
    "#108 или 112"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сформируем 112 признаков. i-й признак будет равен нулю, если герой не участвовал в матче, единице - если играл за Radiant, минус единице - если играл за Dire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pick = np.zeros((train_df.shape[0], 112))\n",
    "\n",
    "for i, match_id in enumerate(train_df.index):\n",
    "    for p in range(5):\n",
    "        X_pick[i, train_df.ix[match_id, 'r%d_hero' % (p+1)]-1] = 1\n",
    "        X_pick[i, train_df.ix[match_id, 'd%d_hero' % (p+1)]-1] = -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Добавим перекодированные признаки к X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.concatenate([X_train, X_pick], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получаем `ROC-AUC = 0.75105`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.751054575291998, 0.0010964869190840853]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_logreg_score(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на корреляцию признаков между друг другом"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d1_lh                d1_gold                0.844783\n",
      "d1_gold              d1_lh                  0.844783\n",
      "d4_gold              d4_lh                  0.847389\n",
      "d4_lh                d4_gold                0.847389\n",
      "d2_lh                d2_gold                0.847995\n",
      "d2_gold              d2_lh                  0.847995\n",
      "d5_lh                d5_gold                0.848907\n",
      "d5_gold              d5_lh                  0.848907\n",
      "d3_lh                d3_gold                0.849217\n",
      "d3_gold              d3_lh                  0.849217\n",
      "r1_lh                r1_gold                0.851178\n",
      "r1_gold              r1_lh                  0.851178\n",
      "r2_lh                r2_gold                0.855202\n",
      "r2_gold              r2_lh                  0.855202\n",
      "r3_gold              r3_lh                  0.855882\n",
      "r3_lh                r3_gold                0.855882\n",
      "r5_lh                r5_gold                0.857561\n",
      "r5_gold              r5_lh                  0.857561\n",
      "r4_gold              r4_lh                  0.857778\n",
      "r4_lh                r4_gold                0.857778\n",
      "d5_xp                d5_level               0.881923\n",
      "d5_level             d5_xp                  0.881923\n",
      "d4_level             d4_xp                  0.882092\n",
      "d4_xp                d4_level               0.882092\n",
      "r4_level             r4_xp                  0.883688\n",
      "r4_xp                r4_level               0.883688\n",
      "r5_level             r5_xp                  0.883714\n",
      "r5_xp                r5_level               0.883714\n",
      "d2_level             d2_xp                  0.883821\n",
      "d2_xp                d2_level               0.883821\n",
      "r2_level             r2_xp                  0.883953\n",
      "r2_xp                r2_level               0.883953\n",
      "d3_level             d3_xp                  0.884710\n",
      "d3_xp                d3_level               0.884710\n",
      "d1_level             d1_xp                  0.886097\n",
      "d1_xp                d1_level               0.886097\n",
      "r3_xp                r3_level               0.886225\n",
      "r3_level             r3_xp                  0.886225\n",
      "first_blood_player1  first_blood_team       0.887942\n",
      "first_blood_team     first_blood_player1    0.887942\n",
      "r1_xp                r1_level               0.888434\n",
      "r1_level             r1_xp                  0.888434\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#correlation matrix\n",
    "corr = train_df.corr().abs()\n",
    "\n",
    "s = corr.unstack()\n",
    "so = s.sort_values(kind=\"quicksort\")\n",
    "print (so[(so < 1) & (so > 0.8)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы видим, что присутствуют сильно скоррелированные между собой признаки: **xp и level, first_blood_player1 и first_blood_team, lh и gold**. Это может привести к неустойчивости финальной модели при использовании логистической регрессии, так что попробуем удалить эти признаки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_features = ['r1_level', 'r2_level', 'r3_level', 'r4_level', 'r5_level',\n",
    "                 'd1_level', 'd2_level', 'd3_level', 'd4_level', 'd5_level',\n",
    "                'first_blood_player1', 'r1_lh', 'r2_lh', 'r3_lh', 'r4_lh', 'r5_lh',\n",
    "                 'd1_lh', 'd2_lh', 'd3_lh', 'd4_lh', 'd5_lh']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7481035489702818, 0.001151820035315145]\n",
      "Wall time: 47.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_train = train_df.drop(columns=cat_features+corr_features).values\n",
    "X_train = np.concatenate([X_train, X_pick], axis=1)\n",
    "print(get_logreg_score(X_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как можно заметить, качество даже немного ухудшилось. Попробуем создать агрегированные признаки для каждой команды: просуммируем каждый признак по всем пяти героям команды и посмотрим как изменится скор"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7515533999133, 0.001150669057955364]\n",
      "Wall time: 45.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_df['r_level_sum'] = 0\n",
    "train_df['d_level_sum'] = 0\n",
    "train_df['r_xp_sum'] = 0 \n",
    "train_df['d_xp_sum'] = 0\n",
    "train_df['r_gold_sum'] = 0\n",
    "train_df['d_gold_sum'] = 0\n",
    "train_df['r_lh_sum'] = 0 \n",
    "train_df['d_lh_sum'] = 0\n",
    "train_df['r_kills_sum'] = 0\n",
    "train_df['d_kills_sum'] = 0\n",
    "train_df['r_deaths_sum'] = 0\n",
    "train_df['d_deaths_sum'] = 0\n",
    "train_df['r_items_sum'] = 0\n",
    "train_df['d_items_sum'] = 0\n",
    "for i in range(5):\n",
    "    train_df['r_level_sum'] += train_df['r%d_level' % (i+1)]\n",
    "    train_df['d_level_sum'] += train_df['d%d_level' % (i+1)]\n",
    "    train_df['r_xp_sum'] += train_df['r%d_xp' % (i+1)]\n",
    "    train_df['d_xp_sum'] += train_df['d%d_xp' % (i+1)]\n",
    "    train_df['r_gold_sum'] += train_df['r%d_gold' % (i+1)]\n",
    "    train_df['d_gold_sum'] += train_df['d%d_gold' % (i+1)]\n",
    "    train_df['r_lh_sum'] += train_df['r%d_lh' % (i+1)]\n",
    "    train_df['d_lh_sum'] += train_df['d%d_lh' % (i+1)]\n",
    "    train_df['r_kills_sum'] += train_df['r%d_kills' % (i+1)]\n",
    "    train_df['d_kills_sum'] += train_df['d%d_kills' % (i+1)]\n",
    "    train_df['r_deaths_sum'] += train_df['r%d_deaths' % (i+1)]\n",
    "    train_df['d_deaths_sum'] += train_df['d%d_deaths' % (i+1)]\n",
    "    train_df['r_items_sum'] += train_df['r%d_items' % (i+1)]\n",
    "    train_df['d_items_sum'] += train_df['d%d_items' % (i+1)]\n",
    "    \n",
    "player_features = ['r1_hero', 'r1_level', 'r1_xp', 'r1_gold', 'r1_lh', 'r1_kills', 'r1_deaths', 'r1_items',\n",
    "                   'r2_hero', 'r2_level', 'r2_xp', 'r2_gold', 'r2_lh', 'r2_kills', 'r2_deaths', 'r2_items',\n",
    "                   'r3_hero', 'r3_level', 'r3_xp', 'r3_gold', 'r3_lh', 'r3_kills', 'r3_deaths', 'r3_items',\n",
    "                   'r4_hero', 'r4_level', 'r4_xp', 'r4_gold', 'r4_lh', 'r4_kills', 'r4_deaths', 'r4_items',\n",
    "                   'r5_hero', 'r5_level', 'r5_xp', 'r5_gold', 'r5_lh', 'r5_kills', 'r5_deaths', 'r5_items',\n",
    "                   'd1_hero', 'd1_level', 'd1_xp', 'd1_gold', 'd1_lh', 'd1_kills', 'd1_deaths', 'd1_items',\n",
    "                   'd2_hero', 'd2_level', 'd2_xp', 'd2_gold', 'd2_lh', 'd2_kills', 'd2_deaths', 'd2_items',\n",
    "                   'd3_hero', 'd3_level', 'd3_xp', 'd3_gold', 'd3_lh', 'd3_kills', 'd3_deaths', 'd3_items',\n",
    "                   'd4_hero', 'd4_level', 'd4_xp', 'd4_gold', 'd4_lh', 'd4_kills', 'd4_deaths', 'd4_items',\n",
    "                   'd5_hero', 'd5_level', 'd5_xp', 'd5_gold', 'd5_lh', 'd5_kills', 'd5_deaths', 'd5_items']\n",
    "X_train = train_df.drop(columns=player_features+['lobby_type', 'first_blood_player1'])\n",
    "X_train = np.concatenate([X_train, X_pick], axis=1)\n",
    "print(get_logreg_score(X_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ROC-AUC вырос на 0.0005"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Настроим параметры C и penalty с помощью GridSearchCV:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "penalty = ['l1', 'l2']\n",
    "C = np.logspace(0,4,5)\n",
    "params = dict(C=C, penalty=penalty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameters: {'C': 1.0, 'penalty': 'l1'}\n",
      "best score: 0.7481104974558247\n",
      "Wall time: 23min 59s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_train_scaled = StandardScaler().fit_transform(X_train)\n",
    "logit_cv = GridSearchCV(LogisticRegression(), params, cv=cv, scoring='roc_auc')\n",
    "logit_cv.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(\"best parameters:\", logit_cv.best_params_)\n",
    "print(\"best score:\", logit_cv.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тюнинг увеличил скор всего на 0.00001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция для вывода предсказаний тестовой выборки в файл (чтобы засабмититься на каггл)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_to_submission_file(predicted_labels, out_file,\n",
    "                             target='radiant_win', index_label='match_id'):\n",
    "    predicted_df = pd.DataFrame(predicted_labels,\n",
    "                                index = test_df.index,\n",
    "                                columns=[target])\n",
    "    predicted_df.to_csv(out_file, index_label=index_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проделываем те же преобразования с тестовой выборкой"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start_time</th>\n",
       "      <th>lobby_type</th>\n",
       "      <th>r1_hero</th>\n",
       "      <th>r1_level</th>\n",
       "      <th>r1_xp</th>\n",
       "      <th>r1_gold</th>\n",
       "      <th>r1_lh</th>\n",
       "      <th>r1_kills</th>\n",
       "      <th>r1_deaths</th>\n",
       "      <th>r1_items</th>\n",
       "      <th>...</th>\n",
       "      <th>radiant_ward_sentry_count</th>\n",
       "      <th>radiant_first_ward_time</th>\n",
       "      <th>dire_bottle_time</th>\n",
       "      <th>dire_courier_time</th>\n",
       "      <th>dire_flying_courier_time</th>\n",
       "      <th>dire_tpscroll_count</th>\n",
       "      <th>dire_boots_count</th>\n",
       "      <th>dire_ward_observer_count</th>\n",
       "      <th>dire_ward_sentry_count</th>\n",
       "      <th>dire_first_ward_time</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>match_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1430287923</td>\n",
       "      <td>0</td>\n",
       "      <td>93</td>\n",
       "      <td>4</td>\n",
       "      <td>1103</td>\n",
       "      <td>1089</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>247.0</td>\n",
       "      <td>-86.0</td>\n",
       "      <td>272.0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>118.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1430293357</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>556</td>\n",
       "      <td>570</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>-29.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>-54.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1430301774</td>\n",
       "      <td>1</td>\n",
       "      <td>112</td>\n",
       "      <td>2</td>\n",
       "      <td>751</td>\n",
       "      <td>808</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>-22.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>-87.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>-34.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1430323933</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>3</td>\n",
       "      <td>708</td>\n",
       "      <td>903</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>-49.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>-89.0</td>\n",
       "      <td>210.0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>-26.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1430331112</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>4</td>\n",
       "      <td>1259</td>\n",
       "      <td>661</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>-86.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>-33.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 102 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          start_time  lobby_type  r1_hero  r1_level  r1_xp  r1_gold  r1_lh  \\\n",
       "match_id                                                                     \n",
       "6         1430287923           0       93         4   1103     1089      8   \n",
       "7         1430293357           1       20         2    556      570      1   \n",
       "10        1430301774           1      112         2    751      808      1   \n",
       "13        1430323933           1       27         3    708      903      1   \n",
       "16        1430331112           1       39         4   1259      661      4   \n",
       "\n",
       "          r1_kills  r1_deaths  r1_items          ...           \\\n",
       "match_id                                         ...            \n",
       "6                0          1         9          ...            \n",
       "7                0          0         9          ...            \n",
       "10               0          0        13          ...            \n",
       "13               1          1        11          ...            \n",
       "16               0          0         9          ...            \n",
       "\n",
       "          radiant_ward_sentry_count  radiant_first_ward_time  \\\n",
       "match_id                                                       \n",
       "6                                 0                     12.0   \n",
       "7                                 2                    -29.0   \n",
       "10                                1                    -22.0   \n",
       "13                                2                    -49.0   \n",
       "16                                0                     36.0   \n",
       "\n",
       "          dire_bottle_time  dire_courier_time  dire_flying_courier_time  \\\n",
       "match_id                                                                  \n",
       "6                    247.0              -86.0                     272.0   \n",
       "7                    168.0              -54.0                       NaN   \n",
       "10                    46.0              -87.0                     186.0   \n",
       "13                    30.0              -89.0                     210.0   \n",
       "16                   180.0              -86.0                     180.0   \n",
       "\n",
       "          dire_tpscroll_count  dire_boots_count  dire_ward_observer_count  \\\n",
       "match_id                                                                    \n",
       "6                           3                 4                         2   \n",
       "7                           3                 2                         2   \n",
       "10                          1                 3                         3   \n",
       "13                          3                 4                         2   \n",
       "16                          1                 3                         2   \n",
       "\n",
       "          dire_ward_sentry_count  dire_first_ward_time  \n",
       "match_id                                                \n",
       "6                              0                 118.0  \n",
       "7                              1                  16.0  \n",
       "10                             0                 -34.0  \n",
       "13                             1                 -26.0  \n",
       "16                             1                 -33.0  \n",
       "\n",
       "[5 rows x 102 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_test = pd.read_csv('data/features_test.csv', index_col='match_id')\n",
    "features_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = features_test.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pick_test = np.zeros((test_df.shape[0], 112))\n",
    "\n",
    "for i, match_id in enumerate(test_df.index):\n",
    "    for p in range(5):\n",
    "        X_pick_test[i, test_df.ix[match_id, 'r%d_hero' % (p+1)]-1] = 1\n",
    "        X_pick_test[i, test_df.ix[match_id, 'd%d_hero' % (p+1)]-1] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 359 ms\n"
     ]
    }
   ],
   "source": [
    "test_df['r_level_sum'] = 0\n",
    "test_df['d_level_sum'] = 0\n",
    "test_df['r_xp_sum'] = 0 \n",
    "test_df['d_xp_sum'] = 0\n",
    "test_df['r_gold_sum'] = 0\n",
    "test_df['d_gold_sum'] = 0\n",
    "test_df['r_lh_sum'] = 0 \n",
    "test_df['d_lh_sum'] = 0\n",
    "test_df['r_kills_sum'] = 0\n",
    "test_df['d_kills_sum'] = 0\n",
    "test_df['r_deaths_sum'] = 0\n",
    "test_df['d_deaths_sum'] = 0\n",
    "test_df['r_items_sum'] = 0\n",
    "test_df['d_items_sum'] = 0\n",
    "for i in range(5):\n",
    "    test_df['r_level_sum'] += test_df['r%d_level' % (i+1)]\n",
    "    test_df['d_level_sum'] += test_df['d%d_level' % (i+1)]\n",
    "    test_df['r_xp_sum'] += test_df['r%d_xp' % (i+1)]\n",
    "    test_df['d_xp_sum'] += test_df['d%d_xp' % (i+1)]\n",
    "    test_df['r_gold_sum'] += test_df['r%d_gold' % (i+1)]\n",
    "    test_df['d_gold_sum'] += test_df['d%d_gold' % (i+1)]\n",
    "    test_df['r_lh_sum'] += test_df['r%d_lh' % (i+1)]\n",
    "    test_df['d_lh_sum'] += test_df['d%d_lh' % (i+1)]\n",
    "    test_df['r_kills_sum'] += test_df['r%d_kills' % (i+1)]\n",
    "    test_df['d_kills_sum'] += test_df['d%d_kills' % (i+1)]\n",
    "    test_df['r_deaths_sum'] += test_df['r%d_deaths' % (i+1)]\n",
    "    test_df['d_deaths_sum'] += test_df['d%d_deaths' % (i+1)]\n",
    "    test_df['r_items_sum'] += test_df['r%d_items' % (i+1)]\n",
    "    test_df['d_items_sum'] += test_df['d%d_items' % (i+1)]\n",
    "    \n",
    "player_features = ['r1_hero', 'r1_level', 'r1_xp', 'r1_gold', 'r1_lh', 'r1_kills', 'r1_deaths', 'r1_items',\n",
    "                   'r2_hero', 'r2_level', 'r2_xp', 'r2_gold', 'r2_lh', 'r2_kills', 'r2_deaths', 'r2_items',\n",
    "                   'r3_hero', 'r3_level', 'r3_xp', 'r3_gold', 'r3_lh', 'r3_kills', 'r3_deaths', 'r3_items',\n",
    "                   'r4_hero', 'r4_level', 'r4_xp', 'r4_gold', 'r4_lh', 'r4_kills', 'r4_deaths', 'r4_items',\n",
    "                   'r5_hero', 'r5_level', 'r5_xp', 'r5_gold', 'r5_lh', 'r5_kills', 'r5_deaths', 'r5_items',\n",
    "                   'd1_hero', 'd1_level', 'd1_xp', 'd1_gold', 'd1_lh', 'd1_kills', 'd1_deaths', 'd1_items',\n",
    "                   'd2_hero', 'd2_level', 'd2_xp', 'd2_gold', 'd2_lh', 'd2_kills', 'd2_deaths', 'd2_items',\n",
    "                   'd3_hero', 'd3_level', 'd3_xp', 'd3_gold', 'd3_lh', 'd3_kills', 'd3_deaths', 'd3_items',\n",
    "                   'd4_hero', 'd4_level', 'd4_xp', 'd4_gold', 'd4_lh', 'd4_kills', 'd4_deaths', 'd4_items',\n",
    "                   'd5_hero', 'd5_level', 'd5_xp', 'd5_gold', 'd5_lh', 'd5_kills', 'd5_deaths', 'd5_items']\n",
    "X_test = test_df.drop(columns=player_features+['lobby_type', 'first_blood_player1'])\n",
    "X_test = np.concatenate([X_test, X_pick_test], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нормируем выборки, чтобы зафититься и получить оценки принадлежности для ROC-AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled = StandardScaler().fit_transform(X_train)\n",
    "X_test_scaled = StandardScaler().fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 42.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "logit = LogisticRegression(C=1, penalty='l1')\n",
    "logit.fit(X_train_scaled, y_train)\n",
    "predictions = logit.predict_proba(X_test_scaled)[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Максимальное и минимальное значение прогноза"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max: 0.9963148561147639\n",
      "Min: 0.008539959627259305\n"
     ]
    }
   ],
   "source": [
    "print('Max:', predictions.max())\n",
    "print ('Min:', predictions.min())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наконец, запишем массив оценок для тестовой выборки в файл"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_to_submission_file(predictions, 'submission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получили `ROC-AUC = 0.75545` на Public LB"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
